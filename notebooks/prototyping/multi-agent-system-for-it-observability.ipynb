{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":121144,"databundleVersionId":14484960,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/syedfarazhussaini/multi-agent-system-for-it-observability?scriptVersionId=283178066\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"id":"15d6ea56","cell_type":"markdown","source":"# üß† Enterprise IT Observability Agent Capstone\n\nWelcome! This notebook is a production-ready adaptation of the **Google/Kaggle 5-Day Agents Intensive** templates. It aligns with the official structure while delivering the **Enterprise IT Observability** capstone project requirements:\n\n- ‚úÖ Adopt the [Agent Development Kit (ADK)](https://google.github.io/adk-docs) foundations taught during the course.\n- ‚úÖ Demonstrate a **Level 3 collaborative multi-agent system** with a pathway toward **Level 4 self-evolving behavior**.\n- ‚úÖ Simulate real-world infrastructure telemetry (logs, metrics, incident emails).\n- ‚úÖ Provide repeatable experiment blocks so you can continue iterating toward deployment.\n\n> üìÖ **Deadline reminder:** Submission due **Dec 1, 2025** (13 days remaining). Stay focused and track progress as you run this notebook.","metadata":{}},{"id":"e766d287","cell_type":"markdown","source":"## üìö Notebook Roadmap\n\n1. **Set up the environment** ‚Äì install dependencies and configure Google Cloud Vertex AI.\n2. **Simulate observability data** ‚Äì generate realistic logs, metrics, and incident emails.\n3. **Define ADK tools** ‚Äì wrap data access and analysis helpers as agent tools.\n4. **Compose the agent team** ‚Äì supervisor plus specialist agents for logs, metrics, and operations.\n5. **Run an observability scenario** ‚Äì orchestrated analysis of a slowdown incident.\n6. **Launch an interactive chat UI** ‚Äì prototype a management-facing dashboard.\n7. **Capture next steps** ‚Äì track tasks to reach Level 4 self-evolving capabilities.\n\nEach section mirrors the pedagogy of the official course notebooks so you can slot this work directly into your submission.","metadata":{}},{"id":"413460da","cell_type":"code","source":"# @title üõ†Ô∏è Install core dependencies\n# This mirrors the setup pattern used in the Google/Kaggle course notebooks.\n# %pip install --quiet google-adk google-cloud-aiplatform pandas gradio #uncomment to install","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:34.702733Z","iopub.execute_input":"2025-12-01T17:06:34.702986Z","iopub.status.idle":"2025-12-01T17:06:34.71099Z","shell.execute_reply.started":"2025-12-01T17:06:34.702966Z","shell.execute_reply":"2025-12-01T17:06:34.709488Z"},"trusted":true},"outputs":[],"execution_count":1},{"id":"f33f9438","cell_type":"code","source":"# @title üîë Load API key (Kaggle Secrets or local .env)\nimport os\n\n# Try Kaggle Secrets first (when running on Kaggle)\ntry:\n    from kaggle_secrets import UserSecretsClient\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key loaded from Kaggle Secrets.\")\nexcept ImportError:\n    # Fallback to .env file (when running locally)\n    try:\n        from dotenv import load_dotenv\n        load_dotenv()\n        GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n        if GOOGLE_API_KEY:\n            print(\"‚úÖ Gemini API key loaded from .env file.\")\n        else:\n            raise ValueError(\"GOOGLE_API_KEY not found in environment variables\")\n    except ImportError:\n        # Manual environment variable check\n        GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n        if GOOGLE_API_KEY:\n            print(\"‚úÖ Gemini API key loaded from environment variables.\")\n        else:\n            print(\"‚ùå Please set GOOGLE_API_KEY environment variable or install python-dotenv\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: {e}\")\n    print(\"Please ensure GOOGLE_API_KEY is available in Kaggle Secrets or environment variables.\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:34.713178Z","iopub.execute_input":"2025-12-01T17:06:34.713577Z","iopub.status.idle":"2025-12-01T17:06:34.825142Z","shell.execute_reply.started":"2025-12-01T17:06:34.713545Z","shell.execute_reply":"2025-12-01T17:06:34.823967Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key loaded from Kaggle Secrets.\n","output_type":"stream"}],"execution_count":2},{"id":"ce1d17ff","cell_type":"markdown","source":"## üîê Authenticate & Configure Vertex AI\n\nJust like the official course materials, we authenticate first and then initialize Vertex AI. If you are running locally, make sure you have executed `gcloud auth application-default login` beforehand.","metadata":{}},{"id":"0cc85a76","cell_type":"code","source":"# @title Authenticate and initialize Vertex AI\nimport os\nimport vertexai\n\nPROJECT_ID = os.getenv(\"GOOGLE_CLOUD_PROJECT\", \"l3-multi-agent-system-4-IT\")  # @param {type:\"string\"}\nLOCATION = \"us-central1\"  # @param {type:\"string\"}\nMODEL_NAME = \"gemini-2.5-flash-lite\"\n\nprint(f\"Using project: {PROJECT_ID} | region: {LOCATION}\")\nvertexai.init(project=PROJECT_ID, location=LOCATION)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:34.826268Z","iopub.execute_input":"2025-12-01T17:06:34.826667Z","iopub.status.idle":"2025-12-01T17:06:44.432943Z","shell.execute_reply.started":"2025-12-01T17:06:34.826634Z","shell.execute_reply":"2025-12-01T17:06:44.431578Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Using project: l3-multi-agent-system-4-IT | region: us-central1\n","output_type":"stream"}],"execution_count":3},{"id":"776a1655","cell_type":"code","source":"# @title Generate synthetic logs, metrics, and incidents\nimport pandas as pd\nimport random\nfrom datetime import datetime, timedelta\nfrom typing import Literal\n\nrandom.seed(42)\n\nSEVERITIES = [\"CRITICAL\", \"ERROR\", \"WARN\", \"INFO\"]\nINCIDENT_TYPES = [\"Network\", \"Database\", \"Application\", \"Infrastructure\"]\n\n\ndef generate_mock_logs(server_id: str, *, window_minutes: int = 240) -> str:\n    \"\"\"Create timestamped log entries with realistic error bursts.\"\"\"\n    now = datetime.utcnow()\n    entries = []\n    for minute in range(window_minutes // 5):\n        timestamp = now - timedelta(minutes=minute * 5)\n        level = random.choices(SEVERITIES, weights=[0.05, 0.15, 0.3, 0.5])[0]\n        if level in {\"CRITICAL\", \"ERROR\"}:\n            message = random.choice([\n                \"Latency spike detected on API Gateway\",\n                \"Database connection timeout\",\n                \"Disk saturation beyond 95%\",\n                \"Service mesh circuit breaker open\",\n            ])\n        elif level == \"WARN\":\n            message = random.choice([\n                \"Retrying connection to cache cluster\",\n                \"CPU utilization approaching threshold\",\n                \"Replica lag increasing\",\n            ])\n        else:\n            message = random.choice([\n                \"Health check passed\",\n                \"Autoscaler polling\",\n                \"Background job completed\",\n            ])\n        entries.append(f\"{timestamp.isoformat()}Z [{level}] {server_id}: {message}\")\n    return \"\\n\".join(reversed(entries))\n\n\ndef generate_mock_metrics(hours: int = 24) -> pd.DataFrame:\n    \"\"\"Return hourly CPU/memory stats with spikes to trigger SLA alerts.\"\"\"\n    now = datetime.utcnow()\n    return pd.DataFrame(\n        {\n            \"timestamp\": [now - timedelta(hours=h) for h in range(hours)][::-1],\n            \"cpu_pct\": [max(10, min(99, random.gauss(55, 18))) for _ in range(hours)],\n            \"memory_pct\": [max(20, min(95, random.gauss(63, 12))) for _ in range(hours)],\n        }\n    )\n\n\ndef generate_incident_email(severity: Literal[\"SEV1\", \"SEV2\", \"SEV3\"]) -> str:\n    incident = random.choice(INCIDENT_TYPES)\n    window = random.choice([\"00:00-02:00 UTC\", \"02:00-04:00 UTC\", \"Maintenance window TBD\"])\n    return (\n        f\"Subject: {severity} {incident} Incident Update\\n\"\n        f\"From: it-operations@company.com\\n\"\n        f\"Body: {incident} team reports anomalies impacting customer latency.\"\n        f\" Suggested remediation window: {window}.\"\n    )","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:44.434057Z","iopub.execute_input":"2025-12-01T17:06:44.434636Z","iopub.status.idle":"2025-12-01T17:06:44.447442Z","shell.execute_reply.started":"2025-12-01T17:06:44.434582Z","shell.execute_reply":"2025-12-01T17:06:44.446319Z"},"trusted":true},"outputs":[],"execution_count":4},{"id":"ebda4694","cell_type":"markdown","source":"## üßÆ Simulate Observability Signals\n\nWe mirror the course pattern of working with synthetic data so you can iterate offline. The helpers below create repeatable logs, metrics, and incident emails to drive the agents.","metadata":{}},{"id":"6866b0d2","cell_type":"markdown","source":"## üîç Wrap data access as ADK tools\n\nFollowing the ADK philosophy, we expose Python helpers as callable tools. The supervisor can then compose them just like in the course samples.","metadata":{}},{"id":"8b6ac13e","cell_type":"markdown","source":"## ü§ñ Compose the multi-agent system\n\nAs in the course notebooks, we define specialist agents and wire them under a supervisor. Each agent inherits the same Gemini model but uses different instructions and toolsets.","metadata":{}},{"id":"7425ea33","cell_type":"code","source":"# @title Register ADK tools\nfrom google.adk.tools import FunctionTool\n\n\ndef fetch_logs_tool(server_id: str = \"prod-app-01\") -> str:\n    \"\"\"Return recent log entries for a server.\"\"\"\n    return generate_mock_logs(server_id)\n\n\ndef summarize_utilization(time_range: str = \"last_24h\") -> dict:\n    \"\"\"Provide aggregate CPU/Memory stats for the requested window.\"\"\"\n    df = generate_mock_metrics()\n    return {\n        \"time_range\": time_range,\n        \"average_cpu_pct\": round(df[\"cpu_pct\"].mean(), 2),\n        \"peak_cpu_pct\": round(df[\"cpu_pct\"].max(), 2),\n        \"average_memory_pct\": round(df[\"memory_pct\"].mean(), 2),\n    }\n\n\ndef fetch_latest_incident() -> str:\n    \"\"\"Return the latest synthetic incident email for context.\"\"\"\n    return generate_incident_email(\"SEV2\")\n\n\nfetch_server_logs = FunctionTool(fetch_logs_tool)\nget_cpu_utilization = FunctionTool(summarize_utilization)\nread_incident_emails = FunctionTool(fetch_latest_incident)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:44.45105Z","iopub.execute_input":"2025-12-01T17:06:44.451333Z","iopub.status.idle":"2025-12-01T17:06:52.090497Z","shell.execute_reply.started":"2025-12-01T17:06:44.451311Z","shell.execute_reply":"2025-12-01T17:06:52.089517Z"},"trusted":true},"outputs":[],"execution_count":5},{"id":"5421bd82","cell_type":"code","source":"# @title Build supervisor and specialist agents\nfrom google.adk.agents import Agent\nfrom google.adk.runners import InMemoryRunner\n\nlog_agent = Agent(\n    name=\"log_analyst\",\n    model=MODEL_NAME,\n    instruction=(\n        \"You inspect raw infrastructure logs to detect anomalies, downtime, and root causes.\"\n        \" Summarize key findings and cite log fragments.\"\n    ),\n    tools=[fetch_server_logs],\n)\n\nmetric_agent = Agent(\n    name=\"metric_analyst\",\n    model=MODEL_NAME,\n    instruction=(\n        \"You analyze time-series metrics to explain utilization trends, SLA breaches, and capacity risks.\"\n        \" Produce concise stats and recommendations.\"\n    ),\n    tools=[get_cpu_utilization],\n)\n\noperations_agent = Agent(\n    name=\"operations_planner\",\n    model=MODEL_NAME,\n    instruction=(\n        \"You coordinate remediation windows, patching schedules, and scaling plans using inputs from peers.\"\n        \" Recommend low-impact execution windows and stakeholder messaging.\"\n    ),\n    tools=[get_cpu_utilization, read_incident_emails],\n)\n\nsupervisor_agent = Agent(\n    name=\"it_ops_supervisor\",\n    model=MODEL_NAME,\n    instruction=(\n        \"You orchestrate specialists to answer executive questions about reliability and performance.\"\n        \" Decide when to call sub-agents and synthesize a single actionable response.\"\n    ),\n    sub_agents=[log_agent, metric_agent, operations_agent],\n)\n\nrunner = InMemoryRunner(agent=supervisor_agent)\nprint(\"‚úÖ Multi-agent system ready\")","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:52.091753Z","iopub.execute_input":"2025-12-01T17:06:52.092258Z","iopub.status.idle":"2025-12-01T17:06:52.102897Z","shell.execute_reply.started":"2025-12-01T17:06:52.092229Z","shell.execute_reply":"2025-12-01T17:06:52.101015Z"},"trusted":true},"outputs":[{"name":"stdout","text":"‚úÖ Multi-agent system ready\n","output_type":"stream"}],"execution_count":6},{"id":"0510f5dc","cell_type":"markdown","source":"## üß™ Run a simulated incident review\n\nThis block mirrors the `run_debug` helper showcased in the course notebooks. It streams agent events so you can validate collaboration before wiring dashboards or schedulers.","metadata":{}},{"id":"05f1828a","cell_type":"code","source":"# @title Investigate a slowdown\nquery = \"We had a customer-facing latency spike overnight. Explain root cause, summarize metrics, and propose a mitigation plan.\"\nprint(f\"User > {query}\\n\")\n\n# run_debug prints a formatted trace similar to Kaggle notebooks.\nawait runner.run_debug(query, user_id=\"exec\", session_id=\"it-ops-session\", verbose=True)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:06:52.103866Z","iopub.execute_input":"2025-12-01T17:06:52.104125Z","iopub.status.idle":"2025-12-01T17:07:02.752055Z","shell.execute_reply.started":"2025-12-01T17:06:52.104102Z","shell.execute_reply":"2025-12-01T17:07:02.751084Z"},"trusted":true},"outputs":[{"name":"stdout","text":"User > We had a customer-facing latency spike overnight. Explain root cause, summarize metrics, and propose a mitigation plan.\n\n\n ### Created new session: it-ops-session\n\nUser > We had a customer-facing latency spike overnight. Explain root cause, summarize metrics, and propose a mitigation plan.\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"it_ops_supervisor > [Calling tool: transfer_to_agent({'agent_name': 'log_analyst'})]\nit_ops_supervisor > [Tool result: {'result': None}]\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"log_analyst > [Calling tool: fetch_logs_tool({'server_id': 'prod-app-01'})]\nlog_analyst > [Tool result: {'result': '2025-12-01T13:11:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\\n2...]\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"log_analyst > The customer-facing latency spike detected around 16:51 appears to be a symptom of deeper issues. The logs indicate several contributing factors:\n\n*   **Disk Saturation:** Multiple entries show \"Disk saturation beyond 95%\" between 14:36 and 15:41.\n*   **Database Connectivity:** \"Database connection timeout\" errors occurred at 15:01 and 16:31, with a critical instance at 16:41.\n*   **Service Mesh Issues:** \"Service mesh circuit breaker open\" errors were logged at 15:26 and 15:46.\n*   **High CPU Utilization & Replica Lag:** Warnings for \"CPU utilization approaching threshold\" and \"Replica lag increasing\" were intermittent throughout the period.\n\nThese issues likely compounded, leading to the eventual latency spike. The disk saturation could have throttled operations, leading to database timeouts and replica lag. The service mesh issues suggest communication problems between services, potentially exacerbated by the underlying resource constraints.\n\nTo address this, I recommend the following:\n\n1.  **Investigate Disk Usage:** Identify the processes or data consuming excessive disk space and implement a cleanup strategy or provision more storage.\n2.  **Database Performance Tuning:** Analyze database performance, optimize queries, and ensure sufficient resources are allocated.\n3.  **Service Mesh Configuration Review:** Examine the service mesh configuration for potential bottlenecks or misconfigurations that could lead to circuit breaking.\n4.  **Resource Scaling:** Consider whether the current CPU and memory resources are adequate, especially during peak times, and evaluate autoscaling configurations.\n\nTo summarize metrics and propose a more detailed mitigation plan, I will transfer this to the `metric_analyst` agent.\nlog_analyst > [Calling tool: transfer_to_agent({'agent_name': 'metric_analyst'})]\nlog_analyst > [Tool result: {'result': None}]\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"metric_analyst > [Calling tool: summarize_utilization({'time_range': 'last_24h'})]\nmetric_analyst > [Tool result: {'time_range': 'last_24h', 'average_cpu_pct': 50.7, 'peak_cpu_pct': 99.0, 'average_memory_pct': 64.3...]\nmetric_analyst > The logs indicate that the latency spike was a symptom of several underlying issues, including disk saturation, database connection timeouts, and service mesh circuit breaker errors. These problems likely compounded, leading to the performance degradation.\n\n**Summary of Metrics:**\n\n*   **Average CPU Utilization:** 50.7%\n*   **Average Memory Utilization:** 64.36%\n*   **Peak CPU Utilization:** 99% (This peak likely occurred during the incident)\n\n**Recommendations:**\n\n1.  **Address Disk Saturation:** Investigate and resolve the cause of disk space exhaustion. This may involve cleaning up old data, optimizing storage, or increasing disk capacity.\n2.  **Database Performance:** Analyze and optimize database performance. Ensure it has adequate resources and troubleshoot connection issues.\n3.  **Service Mesh Configuration:** Review and adjust service mesh configurations to prevent circuit breaker errors.\n4.  **Resource Scaling:** Evaluate the need for increased CPU and memory resources, especially if peak utilization remains consistently high. Adjust autoscaling policies if necessary to handle sudden load increases.\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"[Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       function_call=FunctionCall(\n         args={\n           'agent_name': 'log_analyst'\n         },\n         id='adk-c3cda73a-a036-4535-933f-83199fe111b9',\n         name='transfer_to_agent'\n       )\n     ),\n   ],\n   role='model'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=22,\n   prompt_token_count=322,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=322\n     ),\n   ],\n   total_token_count=344\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='it_ops_supervisor', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='0460f379-2a08-443f-a95b-58791f91d190', timestamp=1764608812.13627),\n Event(model_version=None, content=Content(\n   parts=[\n     Part(\n       function_response=FunctionResponse(\n         id='adk-c3cda73a-a036-4535-933f-83199fe111b9',\n         name='transfer_to_agent',\n         response={\n           'result': None\n         }\n       )\n     ),\n   ],\n   role='user'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='it_ops_supervisor', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent='log_analyst', escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='cffb5987-2e02-4160-8770-fc2648229348', timestamp=1764608813.008343),\n Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       function_call=FunctionCall(\n         args={\n           'server_id': 'prod-app-01'\n         },\n         id='adk-1ecb3305-a372-484c-94b1-4c54c659c9a2',\n         name='fetch_logs_tool'\n       )\n     ),\n   ],\n   role='model'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=24,\n   prompt_token_count=462,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=462\n     ),\n   ],\n   total_token_count=486\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='log_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='bb826a9e-1674-439a-8548-530173ab2eb2', timestamp=1764608813.00995),\n Event(model_version=None, content=Content(\n   parts=[\n     Part(\n       function_response=FunctionResponse(\n         id='adk-1ecb3305-a372-484c-94b1-4c54c659c9a2',\n         name='fetch_logs_tool',\n         response={\n           'result': \"\"\"2025-12-01T13:11:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T13:16:53.826194Z [WARN] prod-app-01: Replica lag increasing\n 2025-12-01T13:21:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T13:26:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T13:31:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T13:36:53.826194Z [WARN] prod-app-01: Retrying connection to cache cluster\n 2025-12-01T13:41:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T13:46:53.826194Z [WARN] prod-app-01: Retrying connection to cache cluster\n 2025-12-01T13:51:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T13:56:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T14:01:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T14:06:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T14:11:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T14:16:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T14:21:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T14:26:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T14:31:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T14:36:53.826194Z [ERROR] prod-app-01: Disk saturation beyond 95%\n 2025-12-01T14:41:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T14:46:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T14:51:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T14:56:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T15:01:53.826194Z [ERROR] prod-app-01: Database connection timeout\n 2025-12-01T15:06:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T15:11:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T15:16:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T15:21:53.826194Z [ERROR] prod-app-01: Disk saturation beyond 95%\n 2025-12-01T15:26:53.826194Z [ERROR] prod-app-01: Service mesh circuit breaker open\n 2025-12-01T15:31:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T15:36:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T15:41:53.826194Z [ERROR] prod-app-01: Disk saturation beyond 95%\n 2025-12-01T15:46:53.826194Z [ERROR] prod-app-01: Service mesh circuit breaker open\n 2025-12-01T15:51:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T15:56:53.826194Z [WARN] prod-app-01: Retrying connection to cache cluster\n 2025-12-01T16:01:53.826194Z [INFO] prod-app-01: Autoscaler polling\n 2025-12-01T16:06:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T16:11:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T16:16:53.826194Z [WARN] prod-app-01: CPU utilization approaching threshold\n 2025-12-01T16:21:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T16:26:53.826194Z [INFO] prod-app-01: Background job completed\n 2025-12-01T16:31:53.826194Z [CRITICAL] prod-app-01: Database connection timeout\n 2025-12-01T16:36:53.826194Z [WARN] prod-app-01: Replica lag increasing\n 2025-12-01T16:41:53.826194Z [CRITICAL] prod-app-01: Database connection timeout\n 2025-12-01T16:46:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T16:51:53.826194Z [ERROR] prod-app-01: Latency spike detected on API Gateway\n 2025-12-01T16:56:53.826194Z [WARN] prod-app-01: Replica lag increasing\n 2025-12-01T17:01:53.826194Z [INFO] prod-app-01: Health check passed\n 2025-12-01T17:06:53.826194Z [INFO] prod-app-01: Health check passed\"\"\"\n         }\n       )\n     ),\n   ],\n   role='user'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='log_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='29d0a8c9-0e26-4cd3-8670-4c8feb726436', timestamp=1764608813.826638),\n Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"The customer-facing latency spike detected around 16:51 appears to be a symptom of deeper issues. The logs indicate several contributing factors:\n \n *   **Disk Saturation:** Multiple entries show \"Disk saturation beyond 95%\" between 14:36 and 15:41.\n *   **Database Connectivity:** \"Database connection timeout\" errors occurred at 15:01 and 16:31, with a critical instance at 16:41.\n *   **Service Mesh Issues:** \"Service mesh circuit breaker open\" errors were logged at 15:26 and 15:46.\n *   **High CPU Utilization & Replica Lag:** Warnings for \"CPU utilization approaching threshold\" and \"Replica lag increasing\" were intermittent throughout the period.\n \n These issues likely compounded, leading to the eventual latency spike. The disk saturation could have throttled operations, leading to database timeouts and replica lag. The service mesh issues suggest communication problems between services, potentially exacerbated by the underlying resource constraints.\n \n To address this, I recommend the following:\n \n 1.  **Investigate Disk Usage:** Identify the processes or data consuming excessive disk space and implement a cleanup strategy or provision more storage.\n 2.  **Database Performance Tuning:** Analyze database performance, optimize queries, and ensure sufficient resources are allocated.\n 3.  **Service Mesh Configuration Review:** Examine the service mesh configuration for potential bottlenecks or misconfigurations that could lead to circuit breaking.\n 4.  **Resource Scaling:** Consider whether the current CPU and memory resources are adequate, especially during peak times, and evaluate autoscaling configurations.\n \n To summarize metrics and propose a more detailed mitigation plan, I will transfer this to the `metric_analyst` agent.\"\"\"\n     ),\n     Part(\n       function_call=FunctionCall(\n         args={\n           'agent_name': 'metric_analyst'\n         },\n         id='adk-ef7c985e-f349-4561-9525-09d41d1ec669',\n         name='transfer_to_agent'\n       )\n     ),\n   ],\n   role='model'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=386,\n   prompt_token_count=2550,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=2550\n     ),\n   ],\n   total_token_count=2936\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='log_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='3a53841f-a89d-4b98-8242-21712566f8a8', timestamp=1764608813.828528),\n Event(model_version=None, content=Content(\n   parts=[\n     Part(\n       function_response=FunctionResponse(\n         id='adk-ef7c985e-f349-4561-9525-09d41d1ec669',\n         name='transfer_to_agent',\n         response={\n           'result': None\n         }\n       )\n     ),\n   ],\n   role='user'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='log_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent='metric_analyst', escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='88f7ce5c-d2db-40b7-a92b-83016f089e30', timestamp=1764608818.812252),\n Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       function_call=FunctionCall(\n         args={\n           'time_range': 'last_24h'\n         },\n         id='adk-fe8a2d57-ed48-44e1-86e5-2c77e2538aa1',\n         name='summarize_utilization'\n       )\n     ),\n   ],\n   role='model'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=23,\n   prompt_token_count=3003,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=3003\n     ),\n   ],\n   total_token_count=3026\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='metric_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=set(), branch=None, id='f2d53703-138d-4d8b-82e4-992f7494f295', timestamp=1764608818.81411),\n Event(model_version=None, content=Content(\n   parts=[\n     Part(\n       function_response=FunctionResponse(\n         id='adk-fe8a2d57-ed48-44e1-86e5-2c77e2538aa1',\n         name='summarize_utilization',\n         response={\n           'average_cpu_pct': 50.7,\n           'average_memory_pct': 64.36,\n           'peak_cpu_pct': 99.0,\n           'time_range': 'last_24h'\n         }\n       )\n     ),\n   ],\n   role='user'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=None, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=None, live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='metric_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='c14049bb-0391-423c-820f-5929701f6372', timestamp=1764608819.93315),\n Event(model_version='gemini-2.5-flash-lite', content=Content(\n   parts=[\n     Part(\n       text=\"\"\"The logs indicate that the latency spike was a symptom of several underlying issues, including disk saturation, database connection timeouts, and service mesh circuit breaker errors. These problems likely compounded, leading to the performance degradation.\n \n **Summary of Metrics:**\n \n *   **Average CPU Utilization:** 50.7%\n *   **Average Memory Utilization:** 64.36%\n *   **Peak CPU Utilization:** 99% (This peak likely occurred during the incident)\n \n **Recommendations:**\n \n 1.  **Address Disk Saturation:** Investigate and resolve the cause of disk space exhaustion. This may involve cleaning up old data, optimizing storage, or increasing disk capacity.\n 2.  **Database Performance:** Analyze and optimize database performance. Ensure it has adequate resources and troubleshoot connection issues.\n 3.  **Service Mesh Configuration:** Review and adjust service mesh configurations to prevent circuit breaker errors.\n 4.  **Resource Scaling:** Evaluate the need for increased CPU and memory resources, especially if peak utilization remains consistently high. Adjust autoscaling policies if necessary to handle sudden load increases.\"\"\"\n     ),\n   ],\n   role='model'\n ), grounding_metadata=None, partial=None, turn_complete=None, finish_reason=<FinishReason.STOP: 'STOP'>, error_code=None, error_message=None, interrupted=None, custom_metadata=None, usage_metadata=GenerateContentResponseUsageMetadata(\n   candidates_token_count=221,\n   prompt_token_count=3087,\n   prompt_tokens_details=[\n     ModalityTokenCount(\n       modality=<MediaModality.TEXT: 'TEXT'>,\n       token_count=3087\n     ),\n   ],\n   total_token_count=3308\n ), live_session_resumption_update=None, input_transcription=None, output_transcription=None, avg_logprobs=None, logprobs_result=None, cache_metadata=None, citation_metadata=None, invocation_id='e-d269db39-e794-43e8-9e93-1a6c3658f6e8', author='metric_analyst', actions=EventActions(skip_summarization=None, state_delta={}, artifact_delta={}, transfer_to_agent=None, escalate=None, requested_auth_configs={}, requested_tool_confirmations={}, compaction=None, end_of_agent=None, agent_state=None, rewind_before_invocation_id=None), long_running_tool_ids=None, branch=None, id='1957e8ef-4289-4a97-b0d0-c25217d521f5', timestamp=1764608819.935362)]"},"metadata":{}}],"execution_count":7},{"id":"c1c59b74","cell_type":"markdown","source":"## üí¨ Launch a lightweight dashboard chat\n\nTo stay consistent with course guidance, we prototype a Gradio chat that management stakeholders can use for on-demand insights. You can later promote this to Cloud Run or Vertex AI Agent Builder.","metadata":{}},{"id":"bd3eca9f","cell_type":"code","source":"### Uncomment locally to run chatbot UI\n# # @title Start Gradio chat prototype\n# import gradio as gr\n# from google.genai import types\n\n# chat_runner = InMemoryRunner(agent=supervisor_agent)\n\n# async def respond(message: str, history: list[tuple[str, str]]):\n#     user_content = types.Content(\n#         role=\"user\",\n#         parts=[types.Part.from_text(text=message)],\n#     )\n#     transcript: list[str] = []\n#     async for event in chat_runner.run_async(\n#         user_id=\"dashboard\",\n#         session_id=\"mgmt-briefing\",\n#         new_message=user_content,\n#     ):\n#         if event.author == \"it_ops_supervisor\" and event.content and event.content.parts:\n#             transcript.extend(part.text or \"\" for part in event.content.parts if part.text)\n#     return \"\\n\".join(transcript)\n\n# iface = gr.ChatInterface(\n#     fn=respond,\n#     title=\"IT Ops Reliability Copilot\",\n#     description=\"Ask about outages, patch windows, or capacity trends.\",\n# )\n# iface.launch(share=False, debug=True)","metadata":{"execution":{"iopub.status.busy":"2025-12-01T17:07:02.753211Z","iopub.execute_input":"2025-12-01T17:07:02.753579Z","iopub.status.idle":"2025-12-01T17:07:02.759689Z","shell.execute_reply.started":"2025-12-01T17:07:02.753547Z","shell.execute_reply":"2025-12-01T17:07:02.758433Z"},"trusted":true},"outputs":[],"execution_count":8},{"id":"93112b44","cell_type":"markdown","source":"## üíª Try the ADK Web Interface","metadata":{}},{"id":"db7b1889","cell_type":"markdown","source":"Follow the same pattern as the Day 1 template: scaffold an agent folder, drop in your production multi-agent code, and then point `adk web` at that directory.","metadata":{}},{"id":"5db03dc7","cell_type":"code","source":"# @title Scaffold ADK agent package (run once per session)\n!adk create it_ops_observability --model gemini-2.5-flash-lite --api_key $GOOGLE_API_KEY","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:07:02.76099Z","iopub.execute_input":"2025-12-01T17:07:02.761307Z","iopub.status.idle":"2025-12-01T17:07:31.182591Z","shell.execute_reply.started":"2025-12-01T17:07:02.761279Z","shell.execute_reply":"2025-12-01T17:07:31.181402Z"}},"outputs":[{"name":"stdout","text":"\u001b[32m\nAgent created in /kaggle/working/it_ops_observability:\n- .env\n- __init__.py\n- agent.py\n\u001b[0m\n","output_type":"stream"}],"execution_count":9},{"id":"1772ee87","cell_type":"code","source":"# @title Write agent module for Try ADK\nfrom pathlib import Path\nimport textwrap\n\nagent_dir = Path(\"it_ops_observability\")\nagent_dir.mkdir(parents=True, exist_ok=True)\n\nagent_source = textwrap.dedent('''\n    Multi-agent IT observability system for ADK Web.\n\n    from __future__ import annotations\n\n    import random\n    from datetime import datetime, timedelta\n    from typing import Literal\n\n    import pandas as pd\n\n    from google.adk.agents import Agent\n    from google.adk.tools import FunctionTool\n\n    MODEL_NAME = \"gemini-2.5-flash-lite\"\n\n    SEVERITIES = [\"CRITICAL\", \"ERROR\", \"WARN\", \"INFO\"]\n    INCIDENT_TYPES = [\"Network\", \"Database\", \"Application\", \"Infrastructure\"]\n\n\n    def generate_mock_logs(server_id: str, window_minutes: int = 240) -> str:\n        \"\"\"Create timestamped log entries with realistic error bursts.\"\"\"\n        now = datetime.utcnow()\n        entries: list[str] = []\n        for minute in range(window_minutes // 5):\n            timestamp = now - timedelta(minutes=minute * 5)\n            level = random.choices(SEVERITIES, weights=[0.05, 0.15, 0.3, 0.5])[0]\n            if level in {\"CRITICAL\", \"ERROR\"}:\n                message = random.choice(\n                    [\n                        \"Latency spike detected on API Gateway\",\n                        \"Database connection timeout\",\n                        \"Disk saturation beyond 95%\",\n                        \"Service mesh circuit breaker open\",\n                    ]\n                )\n            elif level == \"WARN\":\n                message = random.choice(\n                    [\n                        \"Retrying connection to cache cluster\",\n                        \"CPU utilization approaching threshold\",\n                        \"Replica lag increasing\",\n                    ]\n                )\n            else:\n                message = random.choice(\n                    [\n                        \"Health check passed\",\n                        \"Autoscaler polling\",\n                        \"Background job completed\",\n                    ]\n                )\n            entries.append(f\"{timestamp.isoformat()}Z [{level}] {server_id}: {message}\")\n        return \"\\n\".join(reversed(entries))\n\n\n    def generate_mock_metrics(hours: int = 24) -> pd.DataFrame:\n        \"\"\"Return hourly CPU/memory stats with spikes to trigger SLA alerts.\"\"\"\n        now = datetime.utcnow()\n        cpu = [max(10, min(99, random.gauss(55, 18))) for _ in range(hours)]\n        memory = [max(20, min(95, random.gauss(63, 12))) for _ in range(hours)]\n        return pd.DataFrame(\n            {\n                \"timestamp\": [now - timedelta(hours=h) for h in range(hours)][::-1],\n                \"cpu_pct\": cpu,\n                \"memory_pct\": memory,\n            }\n        )\n\n\n    def generate_incident_email(severity: Literal[\"SEV1\", \"SEV2\", \"SEV3\"]) -> str:\n        incident = random.choice(INCIDENT_TYPES)\n        window = random.choice([\"00:00-02:00 UTC\", \"02:00-04:00 UTC\", \"Maintenance window TBD\"])\n        return (\n            f\"Subject: {severity} {incident} Incident Update\\n\"\n            f\"From: it-operations@company.com\\n\"\n            f\"Body: {incident} team reports anomalies impacting customer latency.\"\n            f\" Suggested remediation window: {window}.\"\n        )\n\n\n    def fetch_logs_tool(server_id: str = \"prod-app-01\") -> str:\n        \"\"\"Return recent log entries for a server.\"\"\"\n        return generate_mock_logs(server_id)\n\n\n    def summarize_utilization(time_range: str = \"last_24h\") -> dict:\n        \"\"\"Provide aggregate CPU/Memory stats for the requested window.\"\"\"\n        df = generate_mock_metrics()\n        return {\n            \"time_range\": time_range,\n            \"average_cpu_pct\": round(df[\"cpu_pct\"].mean(), 2),\n            \"peak_cpu_pct\": round(df[\"cpu_pct\"].max(), 2),\n            \"average_memory_pct\": round(df[\"memory_pct\"].mean(), 2),\n        }\n\n\n    def fetch_latest_incident() -> str:\n        \"\"\"Return the latest synthetic incident email for context.\"\"\"\n        return generate_incident_email(\"SEV2\")\n\n\n    def create_agent() -> Agent:\n        \"\"\"Expose the supervisor agent for ADK web.\"\"\"\n        fetch_server_logs = FunctionTool(fetch_logs_tool)\n        get_cpu_utilization = FunctionTool(summarize_utilization)\n        read_incident_emails = FunctionTool(fetch_latest_incident)\n\n        log_agent = Agent(\n            name=\"log_analyst\",\n            model=MODEL_NAME,\n            instruction=(\n                \"You inspect raw infrastructure logs to detect anomalies, downtime, and root causes.\"\n                \" Summarize key findings and cite log fragments.\"\n            ),\n            tools=[fetch_server_logs],\n        )\n\n        metric_agent = Agent(\n            name=\"metric_analyst\",\n            model=MODEL_NAME,\n            instruction=(\n                \"You analyze time-series metrics to explain utilization trends, SLA breaches, and capacity risks.\"\n                \" Produce concise stats and recommendations.\"\n            ),\n            tools=[get_cpu_utilization],\n        )\n\n        operations_agent = Agent(\n            name=\"operations_planner\",\n            model=MODEL_NAME,\n            instruction=(\n                \"You coordinate remediation windows, patching schedules, and scaling plans using inputs from peers.\"\n                \" Recommend low-impact execution windows and stakeholder messaging.\"\n            ),\n            tools=[get_cpu_utilization, read_incident_emails],\n        )\n\n        supervisor_agent = Agent(\n            name=\"it_ops_supervisor\",\n            model=MODEL_NAME,\n            instruction=(\n                \"You orchestrate specialists to answer executive questions about reliability and performance.\"\n                \" Decide when to call sub-agents and synthesize a single actionable response.\"\n            ),\n            sub_agents=[log_agent, metric_agent, operations_agent],\n        )\n\n        return supervisor_agent\n    '''\n)\n\nagent_path = agent_dir / \"agent.py\"\nagent_path.write_text(agent_source)\n\ninit_path = agent_dir / \"__init__.py\"\ninit_path.write_text(\"from .agent import create_agent\\n\\n__all__ = [\\\"create_agent\\\"]\\n\")\n\nprint(f\"‚úÖ ADK web agent written to {agent_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:07:31.184492Z","iopub.execute_input":"2025-12-01T17:07:31.184936Z","iopub.status.idle":"2025-12-01T17:07:31.200602Z","shell.execute_reply.started":"2025-12-01T17:07:31.184894Z","shell.execute_reply":"2025-12-01T17:07:31.199117Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK web agent written to it_ops_observability/agent.py\n","output_type":"stream"}],"execution_count":10},{"id":"3b427129","cell_type":"markdown","source":"If you plan to launch the UI from Kaggle, you'll need the proxied notebook URL. The helper below mirrors the Day 1 template so you can grab the correct link (skip it when running locally).","metadata":{}},{"id":"051cb9de","cell_type":"code","source":"# # @title Compute optional Kaggle proxy URL #uncomment locally to run ADK UI\n# import os\n# from IPython.core.display import display, HTML\n# from jupyter_server.serverapp import list_running_servers\n\n\n# def get_adk_proxy_url() -> str:\n#     \"\"\"Resolve the proxied URL that Kaggle notebooks expect.\"\"\"\n#     proxy_host = \"https://kkb-production.jupyter-proxy.kaggle.net\"\n#     adk_port = \"8000\"\n#     servers = list(list_running_servers())\n#     if not servers:\n#         raise RuntimeError(\"No running Jupyter servers detected.\")\n#     base_url = servers[0][\"base_url\"]\n#     parts = base_url.split(\"/\")\n#     try:\n#         kernel, token = parts[2], parts[3]\n#     except IndexError as exc:\n#         raise RuntimeError(f\"Could not parse kernel/token from base URL: {base_url}\") from exc\n#     url_prefix = f\"/k/{kernel}/{token}/proxy/proxy/{adk_port}\"\n#     button_html = f\"\"\"\n#     <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n#       <div style=\\\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\\\"><strong>‚ö†Ô∏è When running on Kaggle:</strong></div>\n#       <div style=\\\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\\\">\n#         Run the web server cell first, leave it running, then click the button below to open the Try ADK UI in a new tab.\n#       </div>\n#       <a href='{proxy_host}{url_prefix}' target='_blank' style=\\\"display:inline-block; background-color:#1a73e8; color:white; padding:10px 20px; text-decoration:none; border-radius:25px; font-family:sans-serif; box-shadow:0 2px 5px rgba(0,0,0,0.2);\\\">\n#         Open Try ADK UI ‚Üó\n#       </a>\n#     </div>\n#     \"\"\"\n#     display(HTML(button_html))\n#     return url_prefix\n\n\n# try:\n#     url_prefix\n# except NameError:\n#     url_prefix = \"\"\n\n# if not url_prefix:\n#     try:\n#         url_prefix = get_adk_proxy_url()\n#     except Exception as exc:\n#         url_prefix = \"\"\n#         print(\"‚ö†Ô∏è Running outside Kaggle. Continue to the next cell and omit --url_prefix if you are local.\")\n#         print(f\"Details: {exc}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:07:31.201599Z","iopub.execute_input":"2025-12-01T17:07:31.201865Z","iopub.status.idle":"2025-12-01T17:07:31.4597Z","shell.execute_reply.started":"2025-12-01T17:07:31.201846Z","shell.execute_reply":"2025-12-01T17:07:31.458417Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div style=\"padding: 15px; border: 2px solid #f0ad4e; border-radius: 8px; background-color: #fef9f0; margin: 20px 0;\">\n      <div style=\"font-family: sans-serif; margin-bottom: 12px; color: #333; font-size: 1.1em;\"><strong>‚ö†Ô∏è When running on Kaggle:</strong></div>\n      <div style=\"font-family: sans-serif; margin-bottom: 15px; color: #333; line-height: 1.5;\">\n        Run the web server cell first, leave it running, then click the button below to open the Try ADK UI in a new tab.\n      </div>\n      <a href='https://kkb-production.jupyter-proxy.kaggle.net/k/283174379/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..SjYf03JJIKBiE4KN43WOEA.2ywO2XAy95s_gUSvQTlEmqpWyFBQ0aEV9afRcPBhwKudUwcjO3c_-vTKtiRw_j71vWKVvuY9qHW5-ep7w3wcdqhE7EFV0Nf2OClDvJftDPkl_HTEbN4EyFkqsH6xtCZoUSnMQobBwWv1NoGvef-VMoNDEqyECafRy57bMIk5nv2Ky7d1aH0ca_kQ7PTNcRVUMk33tgKiQT1X2tJQKlUynI8WyHLFDFtJ1Lnj7pVTiR8EWqBeqsRt9VfMlSAPq8S1.kLlfHIyaQ1m78-iSfYC7Ig/proxy/proxy/8000' target='_blank' style=\"display:inline-block; background-color:#1a73e8; color:white; padding:10px 20px; text-decoration:none; border-radius:25px; font-family:sans-serif; box-shadow:0 2px 5px rgba(0,0,0,0.2);\">\n        Open Try ADK UI ‚Üó\n      </a>\n    </div>\n    "},"metadata":{}}],"execution_count":11},{"id":"b5c7ce73","cell_type":"markdown","source":"When you are ready to test in the Try ADK UI, run the cell below. It launches the FastAPI web server and binds your multi-agent system so you can interact via the browser.","metadata":{}},{"id":"cdf2d7a2","cell_type":"code","source":"# # @title Launch ADK web (keeps running) #uncomment locally to run ADK UI\n# !adk web it_ops_observability --url_prefix {url_prefix}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T17:07:31.460789Z","iopub.execute_input":"2025-12-01T17:07:31.461324Z","iopub.status.idle":"2025-12-01T17:08:48.202028Z","shell.execute_reply.started":"2025-12-01T17:07:31.4613Z","shell.execute_reply":"2025-12-01T17:08:48.200863Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/google/adk/cli/fast_api.py:130: UserWarning: [EXPERIMENTAL] InMemoryCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  credential_service = InMemoryCredentialService()\n/usr/local/lib/python3.11/dist-packages/google/adk/auth/credential_service/in_memory_credential_service.py:33: UserWarning: [EXPERIMENTAL] BaseCredentialService: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n  super().__init__()\n\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m157\u001b[0m]\n\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server started                                                      |\n|                                                                             |\n| For local testing, access at http://127.0.0.1:8000.                         |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application startup complete.\n\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n\u001b[32mINFO\u001b[0m:     35.191.81.9:0 - \"\u001b[1mGET / HTTP/1.1\u001b[0m\" \u001b[33m307 Temporary Redirect\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.10:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.9:0 - \"\u001b[1mGET /dev-ui/chunk-2WH2EVR6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.8:0 - \"\u001b[1mGET /dev-ui/styles-EVMPSV3U.css HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.10:0 - \"\u001b[1mGET /dev-ui/polyfills-B6TNHZQ6.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.11:0 - \"\u001b[1mGET /dev-ui/main-OS2OH2S3.js HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.11:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.11:0 - \"\u001b[1mGET /dev-ui/adk_favicon.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.12:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.9:0 - \"\u001b[1mGET /dev-ui/assets/ADK-512-color.svg HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.12:0 - \"\u001b[1mGET /dev-ui/ HTTP/1.1\u001b[0m\" \u001b[33m304 Not Modified\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.8:0 - \"\u001b[1mGET /dev-ui/assets/config/runtime-config.json HTTP/1.1\u001b[0m\" \u001b[33m304 Not Modified\u001b[0m\n\u001b[32mINFO\u001b[0m:     35.191.81.9:0 - \"\u001b[1mGET /list-apps?relative_path=./ HTTP/1.1\u001b[0m\" \u001b[32m200 OK\u001b[0m\n^C\n\u001b[32mINFO\u001b[0m:     Shutting down\n\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n\u001b[32m\n+-----------------------------------------------------------------------------+\n| ADK Web Server shutting down...                                             |\n+-----------------------------------------------------------------------------+\n\u001b[0m\n\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m157\u001b[0m]\n\nAborted!\n","output_type":"stream"}],"execution_count":12},{"id":"ad0c2783","cell_type":"markdown","source":"While the ADK web command is running, keep the cell active (Interrupt execution to stop it). Treat the proxy URL as sensitive‚Äînever share it publicly.","metadata":{}},{"id":"80f66f11","cell_type":"markdown","source":"## ‚úÖ Next steps toward Level 4\n\n- **Add self-evolving behaviors:** introduce an agent that synthesizes new tools based on novel telemetry sources.\n- **Persist state:** connect ADK session services to Cloud Firestore or AlloyDB for historical analysis.\n- **Harden deployment:** containerize this notebook logic and publish via Cloud Run or Vertex AI Agent Engine.\n- **Evaluate performance:** leverage ADK evaluation suites to benchmark agent responses on archived incidents.\n\nKeep iterating in alignment with the Kaggle course, and remember to snapshot results for your Dec 1 submission!","metadata":{}}]}